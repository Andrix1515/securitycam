"""
Sistema Inteligente de Detecci√≥n de Tr√°nsito y Alertas de Emergencia por Audio
Distrito de Chilca - Seguridad Ciudadana

Enfoque: Teor√≠a General de Sistemas (Bertalanffy) y Dise√±o de Sistemas (Churchman)
- Entradas: Video (c√°mara), Audio (micr√≥fono), Par√°metros ambientales
- Procesamiento: Detecci√≥n de personas (YOLOv8) + An√°lisis de voz/emoci√≥n
- Salidas: Alertas visuales, sonoras, registros de eventos
- Retroalimentaci√≥n: Ajuste din√°mico de sensibilidad y aprendizaje continuo

Autor: Sistema de IA para Seguridad Ciudadana
Fecha: 2025
Versi√≥n: 1.0.0
"""

import cv2
import numpy as np
import threading
import queue
import time
import os
import json
from datetime import datetime
from pathlib import Path
from typing import List, Tuple, Dict, Optional
import warnings
warnings.filterwarnings('ignore')

# Librer√≠as para detecci√≥n de personas
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("‚ö†Ô∏è  ultralytics no instalado. Instalar con: pip install ultralytics")

# Librer√≠as para audio
try:
    import pyaudio
    import speech_recognition as sr
    AUDIO_AVAILABLE = True
except ImportError:
    AUDIO_AVAILABLE = False
    print("‚ö†Ô∏è  PyAudio o SpeechRecognition no instalados.")
    print("   Instalar con: pip install pyaudio SpeechRecognition")

# Librer√≠a para alertas sonoras
try:
    import pygame
    SOUND_AVAILABLE = True
except ImportError:
    SOUND_AVAILABLE = False
    print("‚ö†Ô∏è  pygame no instalado. Alertas sonoras deshabilitadas.")
    print("   Instalar con: pip install pygame")


class SystemConfig:
    """
    Configuraci√≥n centralizada del sistema - Principio de Jerarqu√≠a de Sistemas
    """
    # Par√°metros de detecci√≥n visual
    CONFIDENCE_THRESHOLD = 0.5
    PERSON_CLASS_ID = 0  # En COCO dataset, ID 0 es 'person'
    MAX_PEOPLE_NORMAL = 10  # Umbral para alertas de aglomeraci√≥n
    
    # Par√°metros de detecci√≥n de audio
    KEYWORDS_EMERGENCY = [
        "ayuda", "socorro", "auxilio", "auxilio por favor",
        "no por favor", "ay√∫denme", "me duele", "llamen"
    ]
    AUDIO_THRESHOLD_DB = 80  # Nivel de decibelios para gritos
    RECOGNITION_TIMEOUT = 3  # Segundos de escucha por ciclo
    
    # Par√°metros de retroalimentaci√≥n
    ADAPTIVE_SENSITIVITY = True
    NOISE_ADJUSTMENT_FACTOR = 1.2
    LEARNING_RATE = 0.1  # Para futuro aprendizaje continuo
    
    # Rutas de archivos
    LOG_FILE = "event_log.txt"
    AUDIO_SAMPLES_DIR = "audio_samples"
    ALERT_SOUND_FILE = "alert_sound.wav"
    
    # Configuraci√≥n de alertas
    ALERT_DURATION_SECONDS = 5
    ALERT_COLOR = (0, 0, 255)  # Rojo en BGR
    ALERT_WINDOW_NAME = "‚ö†Ô∏è ALERTA DE EMERGENCIA ‚ö†Ô∏è"


class PeopleTrafficDetector:
    """
    Subsistema Visual: Detecci√≥n de personas y an√°lisis de tr√°nsito
    
    Funcionalidades:
    - Detecci√≥n en tiempo real con YOLOv8
    - Conteo de personas
    - An√°lisis de densidad y aglomeraci√≥n
    - M√©tricas de rendimiento (FPS, latencia)
    """
    
    def __init__(self, camera_id: int = 0, config: SystemConfig = None):
        self.config = config or SystemConfig()
        self.camera_id = camera_id
        self.model = None
        self.cap = None
        self.running = False
        self.people_count = 0
        self.frame_count = 0
        self.fps = 0
        self.alert_queue = queue.Queue()
        
        # M√©tricas de retroalimentaci√≥n
        self.processing_times = []
        self.avg_processing_time = 0
        
        print("üé• Inicializando m√≥dulo de detecci√≥n visual...")
        self._initialize_model()
        self._initialize_camera()
    
    def _initialize_model(self):
        """Carga el modelo YOLOv8 para detecci√≥n de personas"""
        if not YOLO_AVAILABLE:
            print("‚ùå No se puede inicializar YOLO. M√≥dulo visual deshabilitado.")
            return
        
        try:
            # Usar YOLOv8n (nano) para mayor velocidad
            self.model = YOLO('yolov8n.pt')
            print("‚úÖ Modelo YOLOv8 cargado correctamente")
        except Exception as e:
            print(f"‚ùå Error al cargar modelo: {e}")
            self.model = None
    
    def _initialize_camera(self):
        """Inicializa la captura de video"""
        try:
            self.cap = cv2.VideoCapture(self.camera_id)
            if not self.cap.isOpened():
                print(f"‚ùå No se puede abrir la c√°mara {self.camera_id}")
                return
            
            # Configurar resoluci√≥n
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            print(f"‚úÖ C√°mara {self.camera_id} inicializada")
        except Exception as e:
            print(f"‚ùå Error al inicializar c√°mara: {e}")
            self.cap = None
    
    def detect_people(self, frame: np.ndarray) -> Tuple[np.ndarray, int, List[Dict]]:
        """
        Detecta personas en un frame
        
        Returns:
            frame_annotated: Frame con detecciones dibujadas
            people_count: N√∫mero de personas detectadas
            detections: Lista de detecciones con coordenadas
        """
        if self.model is None:
            return frame, 0, []
        
        start_time = time.time()
        
        # Realizar detecci√≥n
        results = self.model(frame, conf=self.config.CONFIDENCE_THRESHOLD, verbose=False)
        
        people_count = 0
        detections = []
        
        # Procesar resultados
        for result in results:
            boxes = result.boxes
            for box in boxes:
                # Filtrar solo personas (class_id = 0)
                if int(box.cls[0]) == self.config.PERSON_CLASS_ID:
                    people_count += 1
                    
                    # Obtener coordenadas
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf[0])
                    
                    detections.append({
                        'bbox': (int(x1), int(y1), int(x2), int(y2)),
                        'confidence': confidence
                    })
                    
                    # Dibujar bbox
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), 
                                (0, 255, 0), 2)
                    cv2.putText(frame, f'Persona {confidence:.2f}', 
                              (int(x1), int(y1)-10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # Calcular tiempo de procesamiento (retroalimentaci√≥n)
        processing_time = time.time() - start_time
        self.processing_times.append(processing_time)
        if len(self.processing_times) > 30:
            self.processing_times.pop(0)
        self.avg_processing_time = np.mean(self.processing_times)
        
        return frame, people_count, detections
    
    def run(self):
        """Bucle principal de detecci√≥n visual"""
        if self.cap is None or self.model is None:
            print("‚ùå No se puede ejecutar el detector visual")
            return
        
        self.running = True
        frame_times = []
        
        print("üé• Iniciando detecci√≥n de personas...")
        
        while self.running:
            start_time = time.time()
            
            ret, frame = self.cap.read()
            if not ret:
                print("‚ö†Ô∏è  No se puede leer frame de la c√°mara")
                break
            
            # Detectar personas
            frame_annotated, people_count, detections = self.detect_people(frame)
            self.people_count = people_count
            
            # Verificar aglomeraci√≥n (alerta visual)
            if people_count > self.config.MAX_PEOPLE_NORMAL:
                alert = {
                    'type': 'visual',
                    'subtype': 'aglomeracion',
                    'people_count': people_count,
                    'timestamp': datetime.now(),
                    'severity': 'media'
                }
                self.alert_queue.put(alert)
            
            # A√±adir informaci√≥n en pantalla
            info_text = [
                f"Personas detectadas: {people_count}",
                f"FPS: {self.fps:.1f}",
                f"Proc. Time: {self.avg_processing_time*1000:.1f}ms"
            ]
            
            y_offset = 30
            for text in info_text:
                cv2.putText(frame_annotated, text, (10, y_offset),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                y_offset += 30
            
            # Mostrar frame
            cv2.imshow("Detecci√≥n de Tr√°nsito - Chilca", frame_annotated)
            
            # Calcular FPS
            frame_time = time.time() - start_time
            frame_times.append(frame_time)
            if len(frame_times) > 30:
                frame_times.pop(0)
            self.fps = 1.0 / np.mean(frame_times) if frame_times else 0
            
            self.frame_count += 1
            
            # Salir con 'q'
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        self.stop()
    
    def stop(self):
        """Detiene la detecci√≥n visual"""
        self.running = False
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        print("üé• Detector visual detenido")


class AudioEmergencyDetector:
    """
    Subsistema Auditivo: Detecci√≥n de emergencias por audio
    
    Funcionalidades:
    - Captura de audio en tiempo real
    - Reconocimiento de palabras clave de emergencia
    - Detecci√≥n de gritos por nivel de decibelios
    - Control de falsos positivos
    - Retroalimentaci√≥n adaptativa ante ruido ambiente
    """
    
    def __init__(self, config: SystemConfig = None):
        self.config = config or SystemConfig()
        self.recognizer = None
        self.microphone = None
        self.running = False
        self.alert_queue = queue.Queue()
        
        # Par√°metros adaptativos (retroalimentaci√≥n negativa)
        self.noise_threshold = self.config.AUDIO_THRESHOLD_DB
        self.sensitivity = 1.0
        self.ambient_noise_samples = []
        
        # Estad√≠sticas
        self.detections_count = 0
        self.false_positives_filtered = 0
        
        print("üé§ Inicializando m√≥dulo de detecci√≥n de audio...")
        self._initialize_audio()
    
    def _initialize_audio(self):
        """Inicializa el sistema de reconocimiento de voz"""
        if not AUDIO_AVAILABLE:
            print("‚ùå M√≥dulo de audio no disponible")
            return
        
        try:
            self.recognizer = sr.Recognizer()
            self.microphone = sr.Microphone()
            
            # Calibrar ruido ambiente
            print("üé§ Calibrando ruido ambiente... (espere 3 segundos)")
            with self.microphone as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=3)
            
            print("‚úÖ Sistema de audio inicializado correctamente")
        except Exception as e:
            print(f"‚ùå Error al inicializar audio: {e}")
            self.recognizer = None
            self.microphone = None
    
    def _analyze_audio_level(self, audio_data) -> float:
        """
        Analiza el nivel de audio en decibelios (aproximado)
        
        Returns:
            Nivel de audio en dB
        """
        try:
            # Convertir a array numpy
            audio_array = np.frombuffer(audio_data.get_raw_data(), dtype=np.int16)
            
            # Calcular RMS (Root Mean Square)
            rms = np.sqrt(np.mean(audio_array**2))
            
            # Convertir a dB (aproximado)
            if rms > 0:
                db = 20 * np.log10(rms)
            else:
                db = 0
            
            return db
        except Exception as e:
            return 0
    
    def _detect_emergency_keywords(self, text: str) -> bool:
        """
        Verifica si el texto contiene palabras clave de emergencia
        
        Returns:
            True si se detecta emergencia
        """
        text_lower = text.lower()
        
        for keyword in self.config.KEYWORDS_EMERGENCY:
            if keyword in text_lower:
                return True
        
        return False
    
    def _apply_adaptive_filtering(self, audio_level: float) -> bool:
        """
        Retroalimentaci√≥n negativa: ajusta sensibilidad seg√∫n ruido ambiente
        
        Returns:
            True si el audio supera el umbral adaptativo
        """
        self.ambient_noise_samples.append(audio_level)
        if len(self.ambient_noise_samples) > 100:
            self.ambient_noise_samples.pop(0)
        
        # Calcular umbral adaptativo
        if len(self.ambient_noise_samples) > 10:
            avg_noise = np.mean(self.ambient_noise_samples)
            adaptive_threshold = avg_noise * self.config.NOISE_ADJUSTMENT_FACTOR
            
            # Ajustar sensibilidad
            if audio_level > adaptive_threshold:
                return True
        
        return audio_level > self.noise_threshold
    
    def run(self):
        """Bucle principal de detecci√≥n de audio"""
        if self.recognizer is None or self.microphone is None:
            print("‚ùå No se puede ejecutar el detector de audio")
            return
        
        self.running = True
        print("üé§ Iniciando detecci√≥n de emergencias por audio...")
        print(f"üîä Palabras clave monitoreadas: {', '.join(self.config.KEYWORDS_EMERGENCY)}")
        
        while self.running:
            try:
                with self.microphone as source:
                    print("üé§ Escuchando...", end='\r')
                    
                    # Capturar audio
                    audio = self.recognizer.listen(
                        source, 
                        timeout=self.config.RECOGNITION_TIMEOUT,
                        phrase_time_limit=5
                    )
                    
                    # Analizar nivel de audio
                    audio_level = self._analyze_audio_level(audio)
                    
                    # Verificar si es un grito (nivel alto)
                    is_loud = self._apply_adaptive_filtering(audio_level)
                    
                    if is_loud:
                        print(f"\nüîä Sonido fuerte detectado: {audio_level:.1f} dB")
                    
                    # Intentar reconocer voz
                    try:
                        text = self.recognizer.recognize_google(audio, language='es-ES')
                        print(f"üó£Ô∏è  Texto reconocido: '{text}'")
                        
                        # Verificar palabras clave
                        if self._detect_emergency_keywords(text):
                            alert = {
                                'type': 'audio',
                                'subtype': 'palabra_clave',
                                'text': text,
                                'audio_level': audio_level,
                                'timestamp': datetime.now(),
                                'severity': 'alta'
                            }
                            self.alert_queue.put(alert)
                            self.detections_count += 1
                            
                            print(f"‚ö†Ô∏è  ¬°EMERGENCIA DETECTADA! Texto: '{text}'")
                            
                            # PLACEHOLDER: Guardar muestra de audio para aprendizaje
                            # self._save_audio_sample(audio, text)
                        
                        elif is_loud:
                            # Grito sin palabras clave reconocidas
                            alert = {
                                'type': 'audio',
                                'subtype': 'grito',
                                'text': text,
                                'audio_level': audio_level,
                                'timestamp': datetime.now(),
                                'severity': 'media'
                            }
                            self.alert_queue.put(alert)
                            print(f"‚ö†Ô∏è  Grito detectado (sin palabras clave)")
                    
                    except sr.UnknownValueError:
                        # No se pudo reconocer voz
                        if is_loud:
                            # Sonido fuerte no verbal (posible grito)
                            alert = {
                                'type': 'audio',
                                'subtype': 'sonido_fuerte',
                                'audio_level': audio_level,
                                'timestamp': datetime.now(),
                                'severity': 'baja'
                            }
                            self.alert_queue.put(alert)
                    
                    except sr.RequestError as e:
                        print(f"‚ùå Error en servicio de reconocimiento: {e}")
            
            except sr.WaitTimeoutError:
                # Timeout normal, continuar
                pass
            
            except KeyboardInterrupt:
                break
            
            except Exception as e:
                print(f"‚ùå Error en detector de audio: {e}")
                time.sleep(1)
        
        print("üé§ Detector de audio detenido")
    
    def stop(self):
        """Detiene la detecci√≥n de audio"""
        self.running = False
    
    # PLACEHOLDER: Funcionalidad de aprendizaje continuo
    def _save_audio_sample(self, audio_data, label: str):
        """
        [FUTURO] Guarda muestras de audio para entrenamiento
        
        Retroalimentaci√≥n positiva: aprendizaje de nuevos patrones
        """
        # TODO: Implementar guardado de audio en formato WAV
        # TODO: Etiquetar con metadata (timestamp, label, contexto)
        # TODO: Crear dataset para fine-tuning de modelo personalizado
        pass


class SecuritySystem:
    """
    Sistema Central de Seguridad - Integraci√≥n de Subsistemas
    
    Responsabilidades:
    - Coordinar subsistemas visual y auditivo
    - Gestionar alertas centralizadas
    - Registrar eventos en log
    - Emitir alertas sonoras y visuales
    - Proporcionar interfaz de control
    
    Principios de dise√±o:
    - Entrada-Proceso-Salida (Churchman)
    - Retroalimentaci√≥n y homeostasis (Bertalanffy)
    - Control jer√°rquico de subsistemas
    """
    
    def __init__(self, config: SystemConfig = None):
        self.config = config or SystemConfig()
        
        # Subsistemas
        self.visual_detector = None
        self.audio_detector = None
        
        # Hilos de ejecuci√≥n
        self.threads = []
        self.running = False
        
        # Sistema de alertas
        self.alert_window_active = False
        self.sound_system_initialized = False
        
        # Registro de eventos
        self.event_log = []
        
        print("\n" + "="*60)
        print("üö® SISTEMA DE SEGURIDAD CIUDADANA - DISTRITO DE CHILCA")
        print("="*60)
        print("Enfoque: Teor√≠a General de Sistemas")
        print("Subsistemas: Visual (Tr√°nsito) + Auditivo (Emergencias)")
        print("="*60 + "\n")
        
        self._initialize_sound_system()
        self._load_event_log()
    
    def _initialize_sound_system(self):
        """Inicializa pygame para alertas sonoras"""
        if not SOUND_AVAILABLE:
            print("‚ö†Ô∏è  Sistema de sonido no disponible")
            return
        
        try:
            pygame.mixer.init()
            self.sound_system_initialized = True
            print("‚úÖ Sistema de alertas sonoras inicializado")
            
            # PLACEHOLDER: Generar sonido de alerta si no existe
            # self._generate_alert_sound()
        except Exception as e:
            print(f"‚ö†Ô∏è  No se pudo inicializar sistema de sonido: {e}")
    
    def _load_event_log(self):
        """Carga el registro de eventos existente"""
        if os.path.exists(self.config.LOG_FILE):
            try:
                with open(self.config.LOG_FILE, 'r', encoding='utf-8') as f:
                    self.event_log = [line.strip() for line in f.readlines()]
                print(f"‚úÖ Log de eventos cargado: {len(self.event_log)} entradas")
            except Exception as e:
                print(f"‚ö†Ô∏è  Error al cargar log: {e}")
    
    def _save_event(self, event: Dict):
        """
        Registra un evento en el log del sistema
        
        Formato: [TIMESTAMP] [TIPO] [SUBTIPO] [SEVERIDAD] - Detalles
        """
        timestamp = event['timestamp'].strftime('%Y-%m-%d %H:%M:%S')
        event_type = event['type'].upper()
        subtype = event.get('subtype', 'N/A')
        severity = event.get('severity', 'baja').upper()
        
        # Construir mensaje
        if event_type == 'VISUAL':
            details = f"Personas detectadas: {event.get('people_count', 0)}"
        elif event_type == 'AUDIO':
            text = event.get('text', 'N/A')
            audio_level = event.get('audio_level', 0)
            details = f"Texto: '{text}' | Nivel: {audio_level:.1f} dB"
        else:
            details = str(event)
        
        log_entry = f"[{timestamp}] [{event_type}] [{subtype}] [{severity}] - {details}"
        
        # Guardar en memoria y archivo
        self.event_log.append(log_entry)
        
        try:
            with open(self.config.LOG_FILE, 'a', encoding='utf-8') as f:
                f.write(log_entry + '\n')
        except Exception as e:
            print(f"‚ùå Error al guardar evento: {e}")
        
        print(f"üìù Evento registrado: {log_entry}")
    
    def _show_alert_window(self, alert: Dict):
        """
        Muestra ventana de alerta visual
        """
        # Crear ventana de alerta
        alert_frame = np.zeros((400, 600, 3), dtype=np.uint8)
        
        # Fondo rojo parpadeante
        if int(time.time() * 2) % 2 == 0:
            alert_frame[:] = self.config.ALERT_COLOR
        
        # Texto de alerta
        title = "‚ö†Ô∏è ALERTA DE EMERGENCIA ‚ö†Ô∏è"
        cv2.putText(alert_frame, title, (50, 80),
                   cv2.FONT_HERSHEY_BOLD, 1.0, (255, 255, 255), 3)
        
        # Detalles
        details = []
        details.append(f"Tipo: {alert['type'].upper()}")
        details.append(f"Subtipo: {alert.get('subtype', 'N/A')}")
        details.append(f"Severidad: {alert.get('severity', 'N/A').upper()}")
        details.append(f"Hora: {alert['timestamp'].strftime('%H:%M:%S')}")
        
        if alert['type'] == 'audio':
            details.append(f"Texto: {alert.get('text', 'N/A')}")
            details.append(f"Nivel: {alert.get('audio_level', 0):.1f} dB")
        elif alert['type'] == 'visual':
            details.append(f"Personas: {alert.get('people_count', 0)}")
        
        y_offset = 150
        for detail in details:
            cv2.putText(alert_frame, detail, (50, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            y_offset += 40
        
        cv2.imshow(self.config.ALERT_WINDOW_NAME, alert_frame)
        cv2.waitKey(1)
    
    def _play_alert_sound(self):
        """Reproduce sonido de alerta"""
        if not self.sound_system_initialized:
            return
        
        try:
            # PLACEHOLDER: Cargar sonido real
            # if os.path.exists(self.config.ALERT_SOUND_FILE):
            #     sound = pygame.mixer.Sound(self.config.ALERT_SOUND_FILE)
            #     sound.play()
            
            # Por ahora, imprimir mensaje
            print("üîä [SONIDO DE ALERTA REPRODUCIDO]")
        except Exception as e:
            print(f"‚ùå Error al reproducir sonido: {e}")
    
    def _process_alerts(self):
        """
        Hilo de procesamiento de alertas
        
        Consolida alertas de ambos subsistemas y ejecuta acciones
        """
        print("üö® Procesador de alertas activo")
        
        while self.running:
            try:
                # Revisar alertas del detector visual
                if self.visual_detector:
                    try:
                        visual_alert = self.visual_detector.alert_queue.get_nowait()
                        self._save_event(visual_alert)
                        
                        if visual_alert.get('severity') == 'alta':
                            self._show_alert_window(visual_alert)
                            self._play_alert_sound()
                    except queue.Empty:
                        pass
                
                # Revisar alertas del detector de audio
                if self.audio_detector:
                    try:
                        audio_alert = self.audio_detector.alert_queue.get_nowait()
                        self._save_event(audio_alert)

                        # Siempre mostrar alertas de audio
                        self._show_alert_window(audio_alert)
                        self._play_alert_sound()

                        # Mantener ventana de alerta por X segundos
                        start = time.time()
                        while time.time() - start < self.config.ALERT_DURATION_SECONDS:
                            self._show_alert_window(audio_alert)
                            time.sleep(0.1)
                    except queue.Empty:
                        # No hay alertas de audio en la cola
                        pass
                
            except Exception as e:
                print(f"‚ùå Error en procesador de alertas: {e}")
                time.sleep(1)
        
        try:
            # Esperar a que los hilos terminen
            for thread in self.threads:
                thread.join()
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  Interrupci√≥n detectada. Deteniendo sistema...")
            self.stop()
    
    def stop(self):
        """Detiene todos los subsistemas de forma segura"""
        print("\nüõë Deteniendo sistema de seguridad...")
        
        self.running = False
        
        # Detener subsistemas
        if self.visual_detector:
            self.visual_detector.stop()
        
        if self.audio_detector:
            self.audio_detector.stop()
        
        # Cerrar ventanas
        cv2.destroyAllWindows()
        
        # Generar reporte final
        self._generate_final_report()
        
        print("‚úÖ Sistema detenido correctamente")
    
    def start(self, enable_visual: bool = True, enable_audio: bool = True):
        """Inicia el sistema con los subsistemas especificados"""
        if self.running:
            print("‚ö†Ô∏è El sistema ya est√° en ejecuci√≥n")
            return
        
        self.running = True
        
        try:
            # Iniciar detector visual si est√° habilitado
            if enable_visual:
                self.visual_detector = PeopleTrafficDetector(config=self.config)
                visual_thread = threading.Thread(target=self.visual_detector.run)
                visual_thread.daemon = True
                self.threads.append(visual_thread)
                visual_thread.start()
            
            # Iniciar detector de audio si est√° habilitado
            if enable_audio:
                self.audio_detector = AudioEmergencyDetector(config=self.config)
                audio_thread = threading.Thread(target=self.audio_detector.run)
                audio_thread.daemon = True
                self.threads.append(audio_thread)
                audio_thread.start()
            
            # Iniciar procesador de alertas
            alert_thread = threading.Thread(target=self._process_alerts)
            alert_thread.daemon = True
            self.threads.append(alert_thread)
            alert_thread.start()
            
            print("\n‚úÖ Sistema de Seguridad iniciado correctamente")
            print(f"   Visual: {'‚úì' if enable_visual else '‚úó'}")
            print(f"   Audio:  {'‚úì' if enable_audio else '‚úó'}")
            
        except Exception as e:
            print(f"‚ùå Error al iniciar sistema: {e}")
            self.stop()
            raise
    
    def _generate_final_report(self):
        """Genera un reporte final de la sesi√≥n"""
        print("\n" + "="*60)
        print("üìä REPORTE FINAL DE SESI√ìN")
        print("="*60)
        
        if self.visual_detector:
            print(f"üé• Subsistema Visual:")
            print(f"   - Frames procesados: {self.visual_detector.frame_count}")
            print(f"   - FPS promedio: {self.visual_detector.fps:.1f}")
            print(f"   - Tiempo proc. promedio: {self.visual_detector.avg_processing_time*1000:.1f}ms")
        
        if self.audio_detector:
            print(f"üé§ Subsistema de Audio:")
            print(f"   - Detecciones totales: {self.audio_detector.detections_count}")
            print(f"   - Falsos positivos filtrados: {self.audio_detector.false_positives_filtered}")
        
        print(f"\nüìù Total de eventos registrados: {len(self.event_log)}")
        print(f"üìÅ Log guardado en: {self.config.LOG_FILE}")
        print("="*60 + "\n")
    
    # ========================================================================
    # PLACEHOLDERS PARA FUNCIONALIDADES FUTURAS
    # ========================================================================
    
    def integrate_with_map(self, camera_locations: List[Tuple[float, float]]):
        """
        [FUTURO] Integraci√≥n con sistema de mapas del distrito
        
        Args:
            camera_locations: Lista de coordenadas (lat, lon) de c√°maras
        
        Funcionalidad propuesta:
        - Visualizar en mapa todas las c√°maras activas
        - Mostrar alertas georreferenciadas
        - Calcular zonas de mayor incidencia
        - Optimizar patrullaje policial basado en datos
        """
        # TODO: Integrar con API de Google Maps o OpenStreetMap
        # TODO: Crear sistema de geofencing para zonas cr√≠ticas
        # TODO: Implementar an√°lisis espacial de eventos
        pass
    
    def send_notification_to_authorities(self, alert: Dict):
        """
        [FUTURO] Notificaci√≥n autom√°tica a autoridades
        
        Args:
            alert: Diccionario con informaci√≥n de la alerta
        
        Funcionalidad propuesta:
        - Enviar notificaci√≥n push a app m√≥vil de polic√≠a
        - Enviar SMS a n√∫meros de emergencia registrados
        - Crear ticket en sistema de gesti√≥n de incidentes
        - Activar protocolo de respuesta seg√∫n severidad
        
        Consideraciones √©ticas:
        - Verificaci√≥n humana antes de notificar (evitar falsos positivos)
        - Protecci√≥n de datos personales (GDPR/Ley de Protecci√≥n de Datos)
        - Transparencia en criterios de alerta
        """
        # TODO: Implementar API REST para comunicaci√≥n con central
        # TODO: Integrar con Twilio para SMS
        # TODO: Implementar Firebase Cloud Messaging para notificaciones push
        # TODO: Crear sistema de confirmaci√≥n humana (human-in-the-loop)
        pass
    
    def train_custom_voice_model(self, audio_samples_path: str):
        """
        [FUTURO] Entrenamiento de modelo personalizado de detecci√≥n de voz
        
        Retroalimentaci√≥n positiva: Aprendizaje continuo
        
        Args:
            audio_samples_path: Ruta a directorio con muestras de audio etiquetadas
        
        Funcionalidad propuesta:
        - Fine-tuning de modelo de reconocimiento de voz para dialectos locales
        - Aprendizaje de nuevas palabras clave de emergencia
        - Adaptaci√≥n a condiciones ac√∫sticas del distrito de Chilca
        - Reducci√≥n de falsos positivos mediante aprendizaje supervisado
        
        Tecnolog√≠as sugeridas:
        - Mozilla DeepSpeech o Wav2Vec 2.0
        - TensorFlow/PyTorch para entrenamiento
        - Aumento de datos (data augmentation) para robustez
        """
        # TODO: Implementar pipeline de entrenamiento
        # TODO: Crear dataset anotado de emergencias reales (con consentimiento)
        # TODO: Validar modelo con m√©tricas (precision, recall, F1-score)
        pass
    
    def adaptive_noise_cancellation(self):
        """
        [FUTURO] Cancelaci√≥n adaptativa de ruido
        
        Retroalimentaci√≥n negativa: Homeostasis del sistema
        
        Funcionalidad propuesta:
        - Filtrado adaptativo de ruido de tr√°fico vehicular
        - Supresi√≥n de conversaciones normales (no-emergencias)
        - Ajuste din√°mico de sensibilidad seg√∫n hora del d√≠a
        - Aprendizaje de patrones de ruido urbano espec√≠ficos de Chilca
        
        Tecnolog√≠as sugeridas:
        - Filtros Wiener o filtros de Kalman
        - Redes neuronales para separaci√≥n de fuentes (source separation)
        - Algoritmos de beamforming para micr√≥fonos direccionales
        """
        # TODO: Implementar filtros adaptativos
        # TODO: Crear perfil de ruido ambiente por zona y horario
        pass
    
    def create_control_panel_ui(self):
        """
        [FUTURO] Interfaz gr√°fica de control y monitoreo
        
        Opciones de implementaci√≥n:
        1. Streamlit: R√°pido prototipado, ideal para dashboards
        2. Tkinter: Aplicaci√≥n de escritorio nativa
        3. Flask/FastAPI + React: Aplicaci√≥n web completa
        
        Componentes propuestos:
        - Dashboard en tiempo real con m√©tricas del sistema
        - Mapa de calor de incidentes
        - Gr√°ficos de tendencias (horarios de mayor incidencia)
        - Panel de configuraci√≥n (umbrales, palabras clave, etc.)
        - Registro de eventos con filtros y b√∫squeda
        - Sistema de usuarios con diferentes niveles de acceso
        - Visualizaci√≥n de c√°maras en tiempo real
        
        Ejemplo de estructura:
        
        ```
        +------------------------------------------+
        |  SISTEMA DE SEGURIDAD CIUDADANA - CHILCA |
        +------------------------------------------+
        | Estado: ACTIVO üü¢ | Alertas hoy: 3      |
        +------------------+-----------------------+
        | Mapa de          | Estad√≠sticas         |
        | c√°maras          | - Personas: 234      |
        | y alertas        | - Alertas audio: 3   |
        |                  | - FPS: 28.5          |
        +------------------+-----------------------+
        | Registro de eventos (√∫ltimos 10)        |
        | [2025-10-27 14:32] AUDIO - Ayuda detect.|
        | [2025-10-27 14:15] VISUAL - Aglomeraci√≥n|
        +------------------------------------------+
        ```
        """
        # TODO: Elegir framework seg√∫n necesidades
        # TODO: Dise√±ar arquitectura frontend/backend
        # TODO: Implementar autenticaci√≥n y autorizaci√≥n
        # TODO: Crear API RESTful para comunicaci√≥n
        pass
    
    def privacy_compliance_module(self):
        """
        [FUTURO] M√≥dulo de cumplimiento de privacidad y √©tica
        
        Principios fundamentales:
        1. Minimizaci√≥n de datos: Solo capturar lo necesario
        2. Anonimizaci√≥n: No identificar personas espec√≠ficas
        3. Transparencia: Informar a ciudadanos sobre el sistema
        4. Control humano: Decisiones cr√≠ticas requieren validaci√≥n humana
        5. Auditor√≠a: Registro de todas las acciones del sistema
        
        Funcionalidades:
        - NO reconocimiento facial (protecci√≥n de identidad)
        - Anonimizaci√≥n autom√°tica de audio capturado
        - Retenci√≥n limitada de datos (borrado autom√°tico despu√©s de X d√≠as)
        - Encriptaci√≥n de datos sensibles
        - Logs de auditor√≠a inmutables
        - Consentimiento informado para grabaciones
        - Derecho al olvido (GDPR compliance)
        
        Normativa aplicable en Per√∫:
        - Ley N¬∞ 29733: Ley de Protecci√≥n de Datos Personales
        - C√≥digo de Protecci√≥n y Defensa del Consumidor
        - Constituci√≥n Pol√≠tica del Per√∫ (Art. 2, inciso 7: intimidad personal)
        """
        # TODO: Implementar sistema de anonimizaci√≥n
        # TODO: Crear pol√≠tica de retenci√≥n de datos
        # TODO: Desarrollar m√≥dulo de consentimiento
        # TODO: Implementar encriptaci√≥n end-to-end
        pass
    
    def predictive_analytics(self):
        """
        [FUTURO] An√°lisis predictivo y prevenci√≥n proactiva
        
        Funcionalidad propuesta:
        - Predicci√≥n de zonas de alto riesgo seg√∫n patrones hist√≥ricos
        - Identificaci√≥n de horarios cr√≠ticos
        - Correlaci√≥n de eventos (clima, eventos locales, etc.)
        - Sugerencias de despliegue de recursos policiales
        - Alertas tempranas de situaciones potencialmente peligrosas
        
        Modelos sugeridos:
        - Series temporales (ARIMA, Prophet) para tendencias
        - Clustering espacial (DBSCAN) para zonas calientes
        - Redes neuronales recurrentes (LSTM) para patrones complejos
        
        Consideraciones √©ticas:
        - Evitar sesgos algor√≠tmicos (bias hacia ciertas zonas/grupos)
        - No usar para vigilancia masiva o perfilado discriminatorio
        - Transparencia en factores de predicci√≥n
        - Validaci√≥n continua de exactitud de predicciones
        """
        # TODO: Recolectar datos hist√≥ricos de incidentes
        # TODO: Entrenar modelos predictivos
        # TODO: Crear sistema de validaci√≥n y feedback
        # TODO: Implementar auditor√≠a de sesgos
        pass


# ============================================================================
# FUNCI√ìN PRINCIPAL Y EJEMPLOS DE USO
# ============================================================================

def main():
    """Funci√≥n principal de ejecuci√≥n del sistema"""
    # Crear configuraci√≥n personalizada (opcional)
    config = SystemConfig()
    
    # Crear e iniciar el sistema
    system = SecuritySystem(config=config)
    
    try:
        # Iniciar ambos subsistemas
        system.start(enable_visual=True, enable_audio=True)
        
        # Mantener el programa en ejecuci√≥n
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Sistema interrumpido por usuario")
    except Exception as e:
        print(f"\n\n‚ùå Error cr√≠tico en el sistema: {e}")
        import traceback
        traceback.print_exc()
    finally:
        system.stop()


def demo_mode():
    """
    Modo demostraci√≥n para pruebas sin hardware completo
    
    √ötil para:
    - Desarrollar sin c√°mara f√≠sica
    - Probar solo subsistema de audio
    - Validar procesamiento de alertas
    """
    print("\n" + "="*60)
    print("üîß MODO DEMOSTRACI√ìN")
    print("="*60)
    print("Este modo permite probar el sistema sin hardware completo")
    print("="*60 + "\n")
    
    config = SystemConfig()
    system = SecuritySystem(config=config)
    
    # Simulaci√≥n: Solo iniciar subsistema disponible
    if AUDIO_AVAILABLE:
        print("üé§ Iniciando solo subsistema de audio...")
        system.start(enable_visual=False, enable_audio=True)
    elif YOLO_AVAILABLE:
        print("üé• Iniciando solo subsistema visual...")
        system.start(enable_visual=True, enable_audio=False)
    else:
        print("‚ùå No hay subsistemas disponibles. Instale las dependencias.")


# ============================================================================
# INSTRUCCIONES DE INSTALACI√ìN Y USO
# ============================================================================

INSTALLATION_INSTRUCTIONS = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  SISTEMA DE SEGURIDAD CIUDADANA - DISTRITO DE CHILCA                     ‚ïë
‚ïë  Gu√≠a de Instalaci√≥n y Uso                                               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

1. REQUISITOS DEL SISTEMA
   ‚îú‚îÄ Python 3.10 o superior
   ‚îú‚îÄ C√°mara web o c√°mara IP (para detecci√≥n visual)
   ‚îú‚îÄ Micr√≥fono (para detecci√≥n de audio)
   ‚îî‚îÄ Sistema operativo: Windows, Linux o macOS

2. INSTALACI√ìN DE DEPENDENCIAS

   # Crear entorno virtual (recomendado)
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\\Scripts\\activate

   # Instalar dependencias b√°sicas
   pip install opencv-python numpy

   # Detecci√≥n de personas (YOLOv8)
   pip install ultralytics

   # Detecci√≥n de audio
   pip install pyaudio SpeechRecognition

   # Alertas sonoras
   pip install pygame

   # Dependencias adicionales (opcionales)
   pip install matplotlib pandas  # Para an√°lisis y visualizaci√≥n

3. CONFIGURACI√ìN INICIAL

   a) Verificar acceso a c√°mara:
      - Conectar c√°mara USB o asegurar que la c√°mara integrada funcione
      - Probar con: python -c "import cv2; cap = cv2.VideoCapture(0); print(cap.isOpened())"
   
   b) Verificar acceso a micr√≥fono:
      - Configurar permisos en sistema operativo
      - Probar grabaci√≥n de audio
   
   c) Calibrar par√°metros en SystemConfig:
      - MAX_PEOPLE_NORMAL: Umbral para alertas de aglomeraci√≥n
      - AUDIO_THRESHOLD_DB: Sensibilidad de detecci√≥n de gritos
      - KEYWORDS_EMERGENCY: Palabras clave personalizadas

4. EJECUCI√ìN DEL SISTEMA

   # Modo normal (ambos subsistemas)
   python security_system_chilca.py

   # Modo solo visual
   # Editar main() y usar: system.start(enable_visual=True, enable_audio=False)

   # Modo solo audio
   # Editar main() y usar: system.start(enable_visual=False, enable_audio=True)

   # Modo demostraci√≥n
   # Cambiar en __main__: demo_mode() en lugar de main()

5. USO DEL SISTEMA

   ‚îú‚îÄ El sistema iniciar√° autom√°ticamente ambos subsistemas
   ‚îú‚îÄ Ventana de video mostrar√° detecciones en tiempo real
   ‚îú‚îÄ Consola mostrar√° eventos de audio
   ‚îú‚îÄ Alertas se mostrar√°n en ventana separada
   ‚îî‚îÄ Todos los eventos se guardan en event_log.txt

6. DETENER EL SISTEMA

   ‚îú‚îÄ Presionar 'q' en ventana de video, o
   ‚îî‚îÄ Presionar Ctrl+C en consola

7. REVISAR LOGS

   # Ver eventos registrados
   cat event_log.txt  # En Windows: type event_log.txt

   # Analizar con Python
   with open('event_log.txt', 'r') as f:
       events = f.readlines()
       print(f"Total eventos: {len(events)}")

8. SOLUCI√ìN DE PROBLEMAS

   Problema: "No se puede abrir la c√°mara"
   Soluci√≥n: 
   - Verificar que no est√© en uso por otra aplicaci√≥n
   - Probar con otro √≠ndice: PeopleTrafficDetector(camera_id=1)
   
   Problema: "Error en servicio de reconocimiento"
   Soluci√≥n:
   - Verificar conexi√≥n a internet (usa Google Speech Recognition)
   - Considerar usar reconocimiento offline (PocketSphinx)
   
   Problema: "Demasiados falsos positivos de audio"
   Soluci√≥n:
   - Aumentar AUDIO_THRESHOLD_DB en configuraci√≥n
   - Calibrar en ambiente real del distrito

9. INTEGRACI√ìN CON INFRAESTRUCTURA EXISTENTE

   Para integrar con sistema municipal:
   ‚îú‚îÄ Implementar API REST (Flask/FastAPI)
   ‚îú‚îÄ Conectar con base de datos central (PostgreSQL/MongoDB)
   ‚îú‚îÄ Configurar notificaciones a autoridades (ver placeholders)
   ‚îî‚îÄ Desplegar en servidor dedicado o cloud (AWS/Azure/GCP)

10. CONSIDERACIONES √âTICAS Y LEGALES

    ‚ö†Ô∏è  IMPORTANTE:
    ‚îú‚îÄ Informar a ciudadanos sobre presencia de sistema de vigilancia
    ‚îú‚îÄ NO grabar audio/video sin consentimiento o base legal
    ‚îú‚îÄ NO usar reconocimiento facial
    ‚îú‚îÄ Anonimizar todos los datos capturados
    ‚îú‚îÄ Establecer pol√≠ticas de retenci√≥n de datos
    ‚îú‚îÄ Realizar auditor√≠as de sesgos algor√≠tmicos
    ‚îî‚îÄ Cumplir Ley N¬∞ 29733 (Protecci√≥n de Datos Personales - Per√∫)

11. CONTACTO Y SOPORTE

    Para reportar problemas o sugerencias:
    ‚îú‚îÄ GitHub Issues (si el proyecto est√° en repositorio)
    ‚îú‚îÄ Email: seguridad@munichilca.gob.pe (ejemplo)
    ‚îî‚îÄ Documentaci√≥n completa: [URL del proyecto]

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  ENFOQUE SIST√âMICO - RESUMEN                                             ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  ENTRADAS:                                                               ‚ïë
‚ïë  ‚Ä¢ Video en tiempo real (c√°mara)                                         ‚ïë
‚ïë  ‚Ä¢ Audio en tiempo real (micr√≥fono)                                      ‚ïë
‚ïë  ‚Ä¢ Par√°metros de configuraci√≥n                                           ‚ïë
‚ïë  ‚Ä¢ Condiciones ambientales (ruido, iluminaci√≥n)                          ‚ïë
‚ïë                                                                          ‚ïë
‚ïë  PROCESAMIENTO:                                                          ‚ïë
‚ïë  ‚Ä¢ Subsistema Visual: Detecci√≥n de personas con YOLOv8                   ‚ïë
‚ïë  ‚Ä¢ Subsistema Auditivo: Reconocimiento de voz + an√°lisis de decibelios  ‚ïë
‚ïë  ‚Ä¢ Subsistema de Alertas: Consolidaci√≥n y priorizaci√≥n                   ‚ïë
‚ïë  ‚Ä¢ Retroalimentaci√≥n negativa: Ajuste adaptativo de sensibilidad         ‚ïë
‚ïë  ‚Ä¢ Retroalimentaci√≥n positiva: Aprendizaje de nuevos patrones            ‚ïë
‚ïë                                                                          ‚ïë
‚ïë  SALIDAS:                                                                ‚ïë
‚ïë  ‚Ä¢ Alertas visuales (ventanas emergentes)                                ‚ïë
‚ïë  ‚Ä¢ Alertas sonoras (sirena/mensaje)                                      ‚ïë
‚ïë  ‚Ä¢ Registro de eventos (event_log.txt)                                   ‚ïë
‚ïë  ‚Ä¢ M√©tricas de sistema (FPS, latencia, detecciones)                      ‚ïë
‚ïë  ‚Ä¢ [FUTURO] Notificaciones a autoridades                                 ‚ïë
‚ïë                                                                          ‚ïë
‚ïë  CONTROL Y HOMEOSTASIS:                                                  ‚ïë
‚ïë  ‚Ä¢ Ajuste autom√°tico ante ruido ambiente                                 ‚ïë
‚ïë  ‚Ä¢ Filtrado de falsos positivos                                          ‚ïë
‚ïë  ‚Ä¢ Optimizaci√≥n din√°mica de recursos                                     ‚ïë
‚ïë  ‚Ä¢ Supervisi√≥n humana (human-in-the-loop)                                ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""


if __name__ == "__main__":
    # Mostrar instrucciones al iniciar
    print(INSTALLATION_INSTRUCTIONS)
    
    # Preguntar al usuario c√≥mo ejecutar
    print("\n" + "="*60)
    print("Seleccione modo de ejecuci√≥n:")
    print("1. Modo normal (recomendado)")
    print("2. Modo demostraci√≥n (sin hardware completo)")
    print("3. Solo mostrar instrucciones")
    print("="*60)
    
    try:
        choice = input("\nIngrese opci√≥n (1-3) [Enter = 1]: ").strip()
        
        if choice == "" or choice == "1":
            main()
        elif choice == "2":
            demo_mode()
        elif choice == "3":
            print("\n‚úÖ Revise las instrucciones arriba para configurar el sistema.")
        else:
            print("‚ùå Opci√≥n inv√°lida")
    
    except KeyboardInterrupt:
        print("\n\nüëã Sistema cancelado por usuario")
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
